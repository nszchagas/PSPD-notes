{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caio martins 180074741\n",
    "### yuri alves 180078640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"spark://cm1:7077\").appName(\"testekafka\").getOrCreate()\n",
    "\n",
    "lines = spark.readStream.format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"cm4:9092\") \\\n",
    "        .option(\"subscribe\", \"student-a180074741-saida\") \\\n",
    "        .option('includeTimestamp', 'true') \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split, col\n",
    "words = lines.select(explode(split(col(\"value\"), \"\\s+\")) \\\n",
    "        .alias(\"word\"),lines.timestamp)\n",
    "\n",
    "wordCounts = words.groupBy(\"word\").count()\n",
    "schema = (words.groupBy().count()).selectExpr(\"cast (count as string) total\")\n",
    "\n",
    "query = wordCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "count = schema \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "\n",
    "words.writeStream.format('console').option('truncate', 'false').start()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
